{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7f4b7fad-fc76-4149-9964-27c387272ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import lxml.html\n",
    "from lxml.html.clean import Cleaner\n",
    "import requests\n",
    "import time\n",
    "from  tqdm import tqdm\n",
    "\n",
    "LW_API_URL = 'https://www.lesswrong.com/graphql'\n",
    "\n",
    "cleaner = Cleaner(allow_tags=[''], kill_tags=['style', 'script'])\n",
    "def clean_html(text):\n",
    "    return cleaner.clean_html(lxml.html.fromstring(text)).text\n",
    "    \n",
    "def get_posts(before, span = datetime.timedelta(weeks=1), clean=True):\n",
    "    \n",
    "    after = before - span\n",
    "    \n",
    "    before_s = before.strftime('%Y-%m-%d')\n",
    "    after_s = after.strftime('%Y-%m-%d')\n",
    "    \n",
    "    posts_query = \"\"\"\n",
    "    {\n",
    "      posts(input: {\n",
    "        terms: {\n",
    "          view: \"new\"\n",
    "          meta: null  \n",
    "          before: \"%s\"\n",
    "          after: \"%s\"\n",
    "        }\n",
    "      }) {\n",
    "        results {\n",
    "          htmlBody\n",
    "          title\n",
    "          baseScore\n",
    "          af\n",
    "          _id\n",
    "          userId\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\" % (before_s, after_s)\n",
    "    \n",
    "    response = requests.post(LW_API_URL, json = {'query': posts_query})\n",
    "    \n",
    "    try: response_data = response.json()['data']['posts']['results']\n",
    "    except: return []\n",
    "\n",
    "    posts = [convert_post(post, clean=clean) for post in response_data]\n",
    "    \n",
    "    return posts\n",
    "\n",
    "def convert_post(post, clean=True):\n",
    "    key_mapping = {\n",
    "        'htmlBody': 'text',\n",
    "        'title': 'title',\n",
    "        'baseScore': 'karma',\n",
    "        'af': 'af',\n",
    "        '_id': 'id',\n",
    "        'userId': 'userid'\n",
    "    }\n",
    "    \n",
    "    converted = {v: post[k] for k, v in key_mapping.items()}\n",
    "    if clean: \n",
    "        try: converted['text'] = clean_html(converted['text'])\n",
    "        except: pass\n",
    "    \n",
    "    return converted\n",
    "\n",
    "def create_corpus(n_posts=100, filename='lw_corpus.json', span=datetime.timedelta(weeks=1), clean=True, start=None, sleep=0):\n",
    "    if not start: start = datetime.datetime.now()\n",
    "    \n",
    "    posts = []\n",
    "    \n",
    "    with tqdm(total=n_posts) as pbar:\n",
    "        while len(posts) < n_posts:\n",
    "            if sleep: time.sleep(sleep)\n",
    "            new_posts = get_posts(start, clean=clean)\n",
    "            posts += new_posts\n",
    "            start = start - span\n",
    "            pbar.update(len(new_posts))\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(posts, f)\n",
    "        \n",
    "    return posts\n",
    "\n",
    "def create_corpus_jsonl(n_posts=100, filename='lw_corpus.jsonl', span=datetime.timedelta(weeks=1), clean=True, start=None, sleep=0):\n",
    "    if not start: start = datetime.datetime.now()\n",
    "    \n",
    "    posts_so_far = 0\n",
    "    with tqdm(total=n_posts) as pbar:\n",
    "        while posts_so_far < n_posts:\n",
    "            if sleep: time.sleep(sleep)\n",
    "            \n",
    "            posts = get_posts(start, clean=clean)\n",
    "            posts_so_far += len(posts)\n",
    "            \n",
    "            start = start - span\n",
    "            pbar.update(len(posts))\n",
    "\n",
    "            with open(filename, 'a') as f:\n",
    "                lines = [json.dumps(post) + '\\n' for post in posts]\n",
    "                f.writelines(lines)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "23e8ec0c-4dd4-4e7a-811c-e3eb9c212116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10006it [09:09, 18.21it/s]                                                \n"
     ]
    }
   ],
   "source": [
    "#corpus = create_corpus(10000, span=datetime.timedelta(weeks=2), sleep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d337d339-89b1-4bf3-a9d0-601b0bda39d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:06, 26.68it/s]                                                  \n"
     ]
    }
   ],
   "source": [
    "create_corpus_jsonl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bca1a0-692d-4985-9d28-9d1c3ab90f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
