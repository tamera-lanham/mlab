{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#computational-graph\n",
    "\n",
    "In a forward pass, autograd does two things simultaneously:\n",
    "\n",
    "- run the requested operation to compute a resulting tensor, and\n",
    "- maintain the operation’s _gradient function_ in the DAG.\n",
    "\n",
    "The backward pass kicks off when `.backward()` is called on the DAG root. `autograd` then:\n",
    "\n",
    "- computes the gradients from each `.grad_fn`,\n",
    "- accumulates them in the respective tensor’s `.grad` attribute, and\n",
    "- using the chain rule, propagates all the way to the leaf tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, layer_sizes=[16, 128, 128, 16], bias=False, device=None):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            *[nn.Linear(size, layer_sizes[i+1], bias, device) for i, size in enumerate(layer_sizes[:-1])]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "mem = lambda gpu: t.cuda.memory_allocated(gpu) / 2**(30) \n",
    "mems = lambda gpu: f'{gpu} memory usage: {mem(gpu):.2f} GiB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 cuda:0 memory usage: 0.00 GiB\n",
      "2 cuda:0 memory usage: 8.00 GiB\n",
      "3 cuda:0 memory usage: 8.00 GiB\n",
      "4 cuda:0 memory usage: 8.00 GiB\n",
      "5 cuda:0 memory usage: 16.00 GiB\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [16, 2**5, 2**10, 2**20, 2**10, 2**5, 16]\n",
    "gpu = 'cuda:0'\n",
    "\n",
    "X = t.randn((layer_sizes[0],), device=gpu)\n",
    "y = t.randn((layer_sizes[-1],), device=gpu)\n",
    "print('1', mems(gpu))\n",
    "    \n",
    "mlp = MLP(layer_sizes, device=gpu)\n",
    "print('2', mems(gpu))\n",
    "\n",
    "y_pred = mlp(X)\n",
    "print('3', mems(gpu))\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "loss = loss_fn(y, y_pred)\n",
    "print('4', mems(gpu))\n",
    "# p.grad == None for p in mlp.parameters()\n",
    "\n",
    "loss.backward() # creates p.grad for p in mlp.parameters()\n",
    "print('5', mems(gpu))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([32, 16]),\n",
       " torch.Size([1024, 32]),\n",
       " torch.Size([1048576, 1024]),\n",
       " torch.Size([1024, 1048576]),\n",
       " torch.Size([32, 1024]),\n",
       " torch.Size([16, 32])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.grad.shape for p in mlp.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0 memory usage: 0.00 GiB'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear everything from the GPU\n",
    "del X, y, mlp, y_pred, loss_fn, loss\n",
    "mems(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
